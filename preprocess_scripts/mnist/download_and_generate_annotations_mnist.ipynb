{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从 huggingface 下载 mnist 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ALL_PROXY=http://127.0.0.1:7890\n",
      "env: HTTP_PROXY=http://127.0.0.1:7890\n",
      "env: HTTPS_PROXY=http://127.0.0.1:7890\n"
     ]
    }
   ],
   "source": [
    "# 使用代理，连接 huggingface\n",
    "%env ALL_PROXY=http://127.0.0.1:7890\n",
    "%env HTTP_PROXY=http://127.0.0.1:7890\n",
    "%env HTTPS_PROXY=http://127.0.0.1:7890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                   image  label\n",
       " 0      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       " 1      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0\n",
       " 2      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      4\n",
       " 3      {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1\n",
       " 4      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      9\n",
       " ...                                                  ...    ...\n",
       " 59995  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8\n",
       " 59996  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3\n",
       " 59997  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       " 59998  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6\n",
       " 59999  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8\n",
       " \n",
       " [60000 rows x 2 columns],\n",
       "                                                   image  label\n",
       " 0     {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      7\n",
       " 1     {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      2\n",
       " 2     {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1\n",
       " 3     {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0\n",
       " 4     {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      4\n",
       " ...                                                 ...    ...\n",
       " 9995  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      2\n",
       " 9996  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3\n",
       " 9997  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      4\n",
       " 9998  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       " 9999  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6\n",
       " \n",
       " [10000 rows x 2 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 定义数据集的分片文件路径\n",
    "splits = {'train': 'mnist/train-00000-of-00001.parquet', \n",
    "          'test': 'mnist/test-00000-of-00001.parquet'}\n",
    "\n",
    "# 目标存储目录\n",
    "output_dir = \"../../data/mnist/raw/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    # 如果目录不存在，则创建目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_parquet(\"hf://datasets/ylecun/mnist/\" + splits[\"train\"])\n",
    "test_df = pd.read_parquet(\"hf://datasets/ylecun/mnist/\" + splits[\"test\"])\n",
    "\n",
    "# 保存数据到指定路径\n",
    "train_df.to_parquet(output_dir + \"train-00000-of-00001.parquet\")\n",
    "test_df.to_parquet(output_dir + \"test-00000-of-00001.parquet\")\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01\\x00IDATx\\x9cc`\\x18\\xcc\\x80YHH\\xa8\\xaec\\xbd\\xd4\\xb2\\xff\\xdf\\xeb\\x19\\x18\\x18\\x18X`\\x12rlV6\\x02\\xc1\\x0c\\x0c\\x0c\\x0cO&\\x05~\\xbex\\x90\\x81\\x81\\x81\\x81\\x11*g\\xb8\\x97\\x1f\\xca\\xfa\\x97\\xf4\\x95\\xe1\\xd9\\xfb\\x9b\\xc8&\\n\\xdd\\xfe\\xfb\\xf7\\xef\\xdf\\xbf\\xc7\\xb6}\\xff\\x88\\xc5\\xbe\\x809\\xd9\\x7f\\xff\\x9e\\xe5f\\xd0\\x9e\\x85\\xcd5|\\x8c\\xb3\\xfeF\\xa1\\n1\\xc1Y\\x9f\\xfe\\x7fdHab\\xc0\\x05\\xb8\\xf7\\xfdu\\xc3)\\xc9\\xa0\\xfc\\xf1\\xe1\\x82\\x1cF\\\\\\xb2\\x81\\x1f\\xfe\\xfe-\\x97\\xc4%\\xab\\xbb\\xeb\\xef\\xdfi\\xd2\\xb8d\\x05b\\xff\\xfc\\xdd\\x8d\\xdb\\xe2\\x9f\\x7f\\x7f:@\\x99,\\xa82z!\\xa6,\\x0c\\xd7\\x0ea\\xd3\\xa4>\\xe5\\xe9\\xdf\\xbf\\x7f\\x7fm\\xc3\"%Qt\\xf7\\xef\\xdf\\xbf\\x7fO\\xfaaJ\\x89;]\\xfd\\xfb\\xf7\\xef\\xdfc\\x81\\x98\\x81$\\xb4\\xfa\\xf6\\xdf\\xbf\\x7f\\xff\\x1e\\x0e\\xe0\\xc4\\x902_\\xf3\\xe8\\xef\\xdf\\xbf\\x7f\\xbf\\xb4r\\xa3\\x8a\\xb30000\\x04\\x0620\\\\\\xdf\\xfc\\xb7\\xe7\\x036WR\\x1f\\x00\\x00E\\x17^\\x80kL\\x00;\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82',\n",
       " 'path': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练集 Parquet 文件: ../../data/mnist/raw/train-00000-of-00001.parquet\n",
      "加载测试集 Parquet 文件: ../../data/mnist/raw/test-00000-of-00001.parquet\n",
      "保存训练集图像到: ../../data/mnist/processed/train_data\n",
      "保存验证集图像到: ../../data/mnist/processed/val_data\n",
      "保存测试集图像到: ../../data/mnist/processed/test_data\n",
      "所有数据已成功处理并保存！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "# =============== 配置信息 ===============\n",
    "# Parquet 文件路径\n",
    "train_parquet = \"../../data/mnist/raw/train-00000-of-00001.parquet\"\n",
    "test_parquet = \"../../data/mnist/raw/test-00000-of-00001.parquet\"\n",
    "\n",
    "# 输出目录（与您原先的 processed 目录对应）\n",
    "output_root = \"../../data/mnist/processed/\"\n",
    "train_data_dir = os.path.join(output_root, \"train_data\")\n",
    "val_data_dir   = os.path.join(output_root, \"val_data\")\n",
    "test_data_dir  = os.path.join(output_root, \"test_data\")\n",
    "\n",
    "# 注释文件路径\n",
    "train_csv = os.path.join(output_root, \"train_annotations.csv\")\n",
    "val_csv   = os.path.join(output_root, \"val_annotations.csv\")\n",
    "test_csv  = os.path.join(output_root, \"test_annotations.csv\")\n",
    "\n",
    "# 如果这些文件夹不存在，请先创建\n",
    "os.makedirs(train_data_dir, exist_ok=True)\n",
    "os.makedirs(val_data_dir, exist_ok=True)\n",
    "os.makedirs(test_data_dir, exist_ok=True)\n",
    "\n",
    "# =============== 函数定义 ===============\n",
    "def save_image(image_bytes, save_path):\n",
    "    \"\"\"\n",
    "    将二进制图像数据保存为 PNG 文件。\n",
    "    \"\"\"\n",
    "    with open(save_path, 'wb') as f:\n",
    "        f.write(image_bytes)\n",
    "\n",
    "# =============== 读取 Parquet 文件 ===============\n",
    "print(\"加载训练集 Parquet 文件:\", train_parquet)\n",
    "train_df_raw = pd.read_parquet(train_parquet)\n",
    "\n",
    "print(\"加载测试集 Parquet 文件:\", test_parquet)\n",
    "test_df_raw = pd.read_parquet(test_parquet)\n",
    "\n",
    "# =============== 构造训练集并划分验证集 ===============\n",
    "# 假设 train_df_raw 中至少包含两列：[\"image\", \"label\"]\n",
    "# 为每行构造一个文件名，例如：train_0_7.png\n",
    "train_df = train_df_raw.copy()\n",
    "train_df[\"name\"] = train_df.apply(\n",
    "    lambda row: f\"train_{row.name}_{row['label']}.png\", \n",
    "    axis=1\n",
    ")\n",
    "train_df[\"name_label\"] = train_df[\"label\"]\n",
    "\n",
    "# 使用 train_test_split 生成训练集与验证集\n",
    "train_split_df, val_split_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"name_label\"]\n",
    ")\n",
    "\n",
    "# 将注释保存为 CSV\n",
    "train_split_df[[\"name\", \"name_label\"]].to_csv(train_csv, index=False)\n",
    "val_split_df[[\"name\", \"name_label\"]].to_csv(val_csv, index=False)\n",
    "\n",
    "# =============== 将训练/验证数据保存到对应目录 ===============\n",
    "print(\"保存训练集图像到:\", train_data_dir)\n",
    "for _, row in train_split_df.iterrows():\n",
    "    save_path = os.path.join(train_data_dir, row[\"name\"])\n",
    "    image_bytes = row[\"image\"][\"bytes\"]  # 提取二进制图像数据\n",
    "    save_image(image_bytes, save_path)\n",
    "\n",
    "print(\"保存验证集图像到:\", val_data_dir)\n",
    "for _, row in val_split_df.iterrows():\n",
    "    save_path = os.path.join(val_data_dir, row[\"name\"])\n",
    "    image_bytes = row[\"image\"][\"bytes\"]\n",
    "    save_image(image_bytes, save_path)\n",
    "\n",
    "# =============== 构造测试集并输出到指定目录 ===============\n",
    "# 假设 test_df_raw 也有 [\"image\", \"label\"]\n",
    "test_df = test_df_raw.copy()\n",
    "test_df[\"name\"] = test_df.apply(\n",
    "    lambda row: f\"test_{row.name}_{row['label']}.png\",\n",
    "    axis=1\n",
    ")\n",
    "test_df[\"name_label\"] = test_df[\"label\"]\n",
    "\n",
    "# 保存 test_annotations.csv\n",
    "test_df[[\"name\", \"name_label\"]].to_csv(test_csv, index=False)\n",
    "\n",
    "# 输出测试集图像\n",
    "print(\"保存测试集图像到:\", test_data_dir)\n",
    "for _, row in test_df.iterrows():\n",
    "    save_path = os.path.join(test_data_dir, row[\"name\"])\n",
    "    image_bytes = row[\"image\"][\"bytes\"]\n",
    "    save_image(image_bytes, save_path)\n",
    "\n",
    "print(\"所有数据已成功处理并保存！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
